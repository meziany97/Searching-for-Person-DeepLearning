{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f96c0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,numpy as np, cv2 as cv2 , tensorflow as tf,time\n",
    "import face_recognition\n",
    "from tensorflow.python.keras.utils.data_utils import get_file\n",
    "import mediapipe as mp \n",
    "\n",
    "known_faces_dir=\"data/known\"\n",
    "unknown_faces_dir=\"data/unknown\"\n",
    "\n",
    "tolerance=0.6\n",
    "frame_thickness=3\n",
    "font_thickness=2\n",
    "MODEL=\"cnn\"\n",
    "\n",
    "known_faces=[]\n",
    "known_names=[]\n",
    "match=''\n",
    "np.random.seed(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc445434",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "585dbd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageTk, Image\n",
    "class Detector:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def readClasses(self,classesFilePath):\n",
    "        with open(classesFilePath,'r') as f:\n",
    "            self.classesList=f.read().splitlines()\n",
    "            self.colorsList=np.random.uniform(low=0,high=255,size=(len(self.classesList),3))\n",
    "    def  DownloadModel(self,modelUrl):\n",
    "        filename=os.path.basename(modelUrl)\n",
    "        self.modelName=filename[: filename.index('.')]\n",
    "        self.cacheDir=\"./pretrained_models\"\n",
    "        os.makedirs(self.cacheDir,exist_ok=True)\n",
    "        get_file(fname=filename,origin=modelUrl,cache_dir=self.cacheDir,cache_subdir=\"checkpoints\",extract=True)\n",
    "\n",
    "    def LoadModel(self,modelPath):      \n",
    "        self.model=tf.saved_model.load(os.path.join(self.cacheDir,\"checkpoints\", self.modelName,\"saved_model\"))\n",
    "\n",
    "        print(\"the model loaded .......\")\n",
    "    def DrawBoundingBox(self,image,threshold):\n",
    "        inputTensor=cv2.cvtColor(image.copy(), cv2.COLOR_BGR2RGB)             # convert color of image to  RGB\n",
    "        inputTensor= tf.convert_to_tensor(inputTensor,dtype=tf.uint8)                   # flatten the input , convert the image to tensor\n",
    "        inputTensor=inputTensor[tf.newaxis,...]\n",
    "        # -----------------------------------------------------\n",
    "        detections=self.model(inputTensor)\n",
    "        boxs=detections['detection_boxes'][0].numpy()                                         # define all boxes that found on the image\n",
    "        classIndexs = detections['detection_classes'][0].numpy().astype(np.int32)\n",
    "        classScores = detections['detection_scores'][0].numpy()\n",
    "        # ------------------------------------------------------------------\n",
    "        imageHeight, imageWidth ,imc= image.shape\n",
    "        bboxIds=tf.image.non_max_suppression(boxs, classScores,max_output_size=50,iou_threshold=threshold,score_threshold=threshold)\n",
    "#         global NuPerson\n",
    "#         NuPerson=0\n",
    "        if len(bboxIds) !=0:\n",
    "            for i in bboxIds:\n",
    "                bbox= tuple(boxs[i].tolist())\n",
    "                classConfidence = round(100* classScores[i])\n",
    "                classIndex = classIndexs[i]\n",
    "                if (classIndex == 2):\n",
    "                    self.msg=\"object is found\"\n",
    "                else:\n",
    "                    self.msg=\"object is not found\"\n",
    "                classLabel = self.classesList[classIndex].upper()\n",
    "                classColor = self.colorsList[classIndex]\n",
    "                displayText = \"{}: {}%\".format(classLabel, classConfidence)\n",
    "        #         ----------------------------------------------->\n",
    "                ymin, xmin, ymax,xmax = bbox\n",
    "                xmin,xmax, ymin, ymax = (xmin*imageWidth, xmax* imageWidth, ymin * imageHeight, ymax*imageHeight)\n",
    "                xmin, xmax, ymin, ymax = int(xmin), int(xmax), int(ymin), int(ymax)\n",
    "                lineWidth = min(int((xmax - xmin) * 0.3), int((ymax - ymin) * 0.3))\n",
    "                theckNess = 2\n",
    "                cv2.line(image, (xmin, ymin), (xmin + lineWidth, ymin), classColor, thickness=theckNess)\n",
    "                cv2.line(image, (xmin, ymin), (xmin, ymin + lineWidth), classColor, thickness=theckNess)\n",
    "\n",
    "                cv2.line(image, (xmax, ymin), (xmax - lineWidth, ymin), classColor, thickness=theckNess)\n",
    "                cv2.line(image, (xmax, ymin), (xmax, ymin + lineWidth), classColor, thickness=theckNess)\n",
    "\n",
    "                cv2.line(image, (xmin, ymax), (xmin + lineWidth, ymax), classColor, thickness=theckNess)\n",
    "                cv2.line(image, (xmin, ymax), (xmin, ymax - lineWidth), classColor, thickness=theckNess)\n",
    "                cv2.line(image, (xmax, ymax), (xmax - lineWidth, ymax), classColor, thickness=theckNess)\n",
    "                cv2.line(image, (xmax, ymax), (xmax, ymax - lineWidth), classColor, thickness=theckNess)\n",
    "\n",
    "#                 =====================================\n",
    "\n",
    "                cv2.rectangle(image ,(xmin,ymin), (xmax, ymax),color=classColor, thickness=1)\n",
    "                cv2.putText(image, displayText,(xmin, ymin - 10),cv2.FONT_HERSHEY_COMPLEX_SMALL,1,classColor,1)\n",
    "        return image\n",
    "    def recognition_faces(self):\n",
    "        for name in os.listdir(known_faces_dir):\n",
    "            for filename in os.listdir(f\"{known_faces_dir}/{name}\"):\n",
    "                image = face_recognition.load_image_file(f\"{known_faces_dir}/{name}/{filename}\")\n",
    "                encoding = face_recognition.face_encodings(image)[0]\n",
    "                known_faces.append(encoding)\n",
    "                known_names.append(name)\n",
    "    def DrawingFaceBoundingBox(self,img):\n",
    "        mpFaceDetection = mp.solutions.face_detection\n",
    "        FaceDetection = mpFaceDetection.FaceDetection()\n",
    "        mpDraw = mp.solutions.drawing_utils\n",
    "#         cv2.putText(img, \"N. Person:\" + str(NuPerson), (10, 20), cv2.FONT_HERSHEY_PLAIN, 2, (0, 255, 0), 2)        \n",
    "        results = FaceDetection.process(img)\n",
    "        if results.detections:\n",
    "            for id, detection in enumerate(results.detections):\n",
    "                bboxC = detection.location_data.relative_bounding_box\n",
    "                ih, iw, ic = img.shape\n",
    "                bbox = int(bboxC.xmin * iw), int(bboxC.ymin * ih),\\\n",
    "                       int(bboxC.width * iw), int(bboxC.height * ih)\n",
    "                img = self.fancyDraw(img,bbox)\n",
    "        return img \n",
    "    # for drawing the bounding box      \n",
    "    def fancyDraw(self, img, bbox, l=20, t=2,rt=1):\n",
    "        x, y, w, h = bbox\n",
    "        x1,y1 = x+w,y+h \n",
    "        cv2.rectangle(img, bbox, (0,255,255),rt)\n",
    "       # courner 1 = TOP LEFT X,Y       \n",
    "        cv2.line(img, (x,y),(x+l,y),(0,255,255),t)\n",
    "        cv2.line(img, (x,y),(x,y+l),(0,255,255),t)\n",
    "        # courner 2 = TOP RIGHT X1,Y\n",
    "        cv2.line(img, (x1,y),(x1-l,y),(0,255,255),t)\n",
    "        cv2.line(img, (x1,y),(x1,y+l),(0,255,255),t)\n",
    "        \n",
    "        # courner 3 = BOTTOM LEFT x,y1\n",
    "        cv2.line(img, (x,y1),(x+l,y1),(0,255,255),t)\n",
    "        cv2.line(img, (x,y1),(x,y1-l),(0,255,255),t)\n",
    "        # courner 4 = BOTTOM RIGHT X1,Y1\n",
    "        cv2.line(img, (x1,y1),(x1-l,y1),(0,255,255),t)\n",
    "        cv2.line(img, (x1,y1),(x1,y1-l),(0,255,255),t)\n",
    "        return img\n",
    "    def DetectOnImage(self, imagePath,threshold):\n",
    "        image=cv2.imread(imagePath)\n",
    "        # ----------------------------------\n",
    "        self.recognition_faces()\n",
    "        locations = face_recognition.face_locations(image, model=self.model);\n",
    "        encodings = face_recognition.face_encodings(image, locations);\n",
    "        # landmark=face_recognition.face_landmarks(image,locations,model= MODEL)\n",
    "        imageboxed = self.DrawBoundingBox(image, threshold)\n",
    "        for face_encoding, face_location in zip(encodings, locations):\n",
    "            rslt = face_recognition.compare_faces(known_faces, face_encoding, tolerance)\n",
    "            match = None;\n",
    "            if True in rslt:\n",
    "                match = known_names[rslt.index(True)];\n",
    "                cv2.putText(imageboxed, \"Matched:\" + str(match), (20, 70), cv2.FONT_HERSHEY_PLAIN, 2, (0, 255, 0), 2)\n",
    "            else:\n",
    "                 match=\"Unknown\"\n",
    "            cv2.putText(imageboxed, \"Matched:\" + str(match), (20, 70), cv2.FONT_HERSHEY_PLAIN, 2, (0, 255, 0), 2)\n",
    "        # ---------------------------------\n",
    "        cv2.imshow(\"result:\",imageboxed)\n",
    "        cv2.imwrite(\"detect\"+'.jpg', imageboxed)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09aa74bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the model loaded .......\n"
     ]
    }
   ],
   "source": [
    "classesFilePath=\"model_data/coco.names\"\n",
    "ModelUrl=\"hqqttp://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8.tar.gz\"\n",
    "modelPath=\"pretrained_model/\"\n",
    "\n",
    "imagePath=\"data/im2.jpg\"\n",
    "videoPath=\"data/eln.mp4\"\n",
    "img = \"database/saidd/\"\n",
    "threshold=0.5\n",
    "detector=Detector()\n",
    "\n",
    "\n",
    "detector.readClasses(classesFilePath)\n",
    "detector.DownloadModel(ModelUrl)\n",
    "detector.LoadModel(modelPath)\n",
    "#     detector.DetectOnImage(imagePath,threshold)\n",
    "# detector.DetectOnVideo(videoPath ,threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f539c81a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from tkinter import *\n",
    "from tkinter.ttk import * \n",
    "from tkinter.filedialog import askopenfile \n",
    "from tkvideo import tkvideo\n",
    "import time\n",
    "import datetime\n",
    "from turtle import color, width \n",
    "from PIL import ImageTk, Image\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog \n",
    "import cv2 as cv2\n",
    "import os \n",
    "window = Tk()\n",
    "window.title(\"Search for object\")\n",
    "window.geometry('1250x850')\n",
    "window.resizable(0,0)\n",
    "# create the left frame \n",
    "left_frame = tk.Frame(window,width=620,height=825)\n",
    "left_frame.grid(row=0,column=1)\n",
    "\n",
    "# create the top left frame \n",
    "top_left_frame = tk.Frame(left_frame,width=620,height=80)\n",
    "top_left_frame.grid(row=0,column=1)\n",
    "#  create elements of top left frame \n",
    "tk.Button(top_left_frame, text=\"Select Image\", font=\"Helvetica  14 bold\",bg=\"yellow\" ,fg=\"black\", width=15,command=lambda:upload_Images() ).grid(row=0,column=2,pady=5)\n",
    "\n",
    "# create function of uploading images \n",
    "def upload_Images():\n",
    "    global filename,img\n",
    "    F_Types=[('PNG files','*.png'),('Jpg files','*.jpg'),('Jpeg files','*.jpeg')]\n",
    "    filename = tk.filedialog.askopenfilename(filetypes=F_Types)\n",
    "\n",
    "    img= Image.open(filename)\n",
    "    img=img.resize((300,300))\n",
    "    image = ImageTk.PhotoImage(img)\n",
    "    \n",
    "    e1=tk.Button(bot_top_2_right_frame,bg=\"red\")\n",
    "    e1.grid(row=1,column=0,padx=10)\n",
    "    e1.image=image\n",
    "    e1['image']=image\n",
    "    if image :\n",
    "        AddToDataBaseBtn()\n",
    "    if image is not None:\n",
    "        pass\n",
    "# create the bottom left frame \n",
    "bottom_left_frame = tk.Frame(left_frame,width=620,height=745)\n",
    "bottom_left_frame.config(background=\"yellow\")\n",
    "bottom_left_frame.grid(row=1,column=1)\n",
    "\n",
    "#  create elements of bottom left frame \n",
    "f1 = tk.LabelFrame(bottom_left_frame,bg=\"red\")\n",
    "f1.grid(row=0,column=1)\n",
    "l1= tk.Label(f1, bg=\"red\")\n",
    "l1.grid(row=1,column=1)\n",
    "\n",
    "# load video \n",
    "# player = tkvideo(\"database/el1.mp4\", l1,loop=1, size=(650,745))\n",
    "# player.play()\n",
    "\n",
    "# ===============================================\n",
    "\n",
    "\n",
    "def DetectOnvideo():\n",
    "    cap=cv2.VideoCapture(\"data/eln.mp4\")\n",
    "    if (cap.isOpened() == False):\n",
    "        print(\"Error in openning the video ....\")\n",
    "        return\n",
    "    (success, image)=cap.read()\n",
    "    starttime=0\n",
    "    while success:\n",
    "        currenttime=time.time()\n",
    "        fps = 1 / (currenttime - starttime)\n",
    "        starttime = currenttime\n",
    "        bbox=detector.DrawBoundingBox(image,threshold);\n",
    "        detector.recognition_faces()\n",
    "        img_RGB = cv2.cvtColor(bbox, cv2.COLOR_RGB2BGR)\n",
    "        img2 = detector.DrawingFaceBoundingBox(img_RGB)\n",
    "        locations = face_recognition.face_locations(image, model=MODEL);\n",
    "        encodings = face_recognition.face_encodings(image, locations);\n",
    "        match = None;\n",
    "        global dateFound,Location,msgg\n",
    "        for face_encoding, face_location in zip(encodings, locations):\n",
    "            rslt = face_recognition.compare_faces(known_faces, face_encoding, tolerance)    \n",
    "\n",
    "            \n",
    "            if True in rslt:                                \n",
    "                match = known_names[rslt.index(True)];    \n",
    "                msgg=\" MATCHED !\"\n",
    "                dateFound = datetime.datetime.now()\n",
    "                Location = \"Location of the camera !\"\n",
    "            else:\n",
    "                msgg=None\n",
    "                dateFound = None\n",
    "                Location = None\n",
    "            img2=cv2.resize(img2,(650,745),fx=0,fy=0,interpolation=cv2.INTER_CUBIC)\n",
    "            bb = ImageTk.PhotoImage(Image.fromarray(img2),master=bottom_left_frame)\n",
    "            l1['image'] =bb\n",
    "            window.update()\n",
    "        (success,image)=cap.read()\n",
    "# ===============================================\n",
    "# create the right frame \n",
    "right_frame = tk.Frame(window,width=620,height=825)\n",
    "right_frame.grid(row=0,column=2)\n",
    "\n",
    "# create the top right frame \n",
    "# top_right_frame = tk.Frame(right_frame,width=620,height=400)\n",
    "# top_right_frame.grid(row=0,column=1)\n",
    "\n",
    "top_right_frame = tk.LabelFrame(right_frame, bg=\"gray\" ,width=620,height=400)\n",
    "top_right_frame.grid(row=0,column=1)\n",
    "top_right_frame.grid_propagate(False)\n",
    "# create the top 2 right frame \n",
    "top_2_right_frame = tk.Frame(top_right_frame,width=620,height=60)\n",
    "top_2_right_frame.grid(row=1,column=1)\n",
    "# create the bottom top 2 right frame \n",
    "bot_top_2_right_frame = tk.Frame(top_right_frame,width=620,height=340,bg=\"gray\")\n",
    "bot_top_2_right_frame.grid(row=2,column=1, padx=20, pady=15)\n",
    "\n",
    "#  create elements of top right frame  \n",
    "tk.Label(top_2_right_frame, text=\"Searching person\", font=\"Helvetica 14 bold\").grid(row=0,column=0, pady=5,padx=10)\n",
    "def AddToDataBaseBtn():\n",
    "    btnsFrame= tk.Frame(bot_top_2_right_frame,bg=\"gray\")\n",
    "    btnsFrame.grid(row=1,rowspan=2,column=1)\n",
    "    tk.Button(btnsFrame, text=\"Add Image\", font=\"Helvetica  14 bold\",bg=\"green\" ,fg=\"white\", width=15,command=lambda:AddToDataBase()).grid(row=1,column=2,padx=10)\n",
    "    tk.Button(btnsFrame, text=\"Searching\", font=\"Helvetica  14 bold\", fg=\"white\",bg=\"red\", width=15,command=lambda:Search()).grid(row=2,column=2,padx=10 ,pady=10)   \n",
    "# save the image     \n",
    "def AddToDataBase():\n",
    "    parent_dir= \"data/known/\"\n",
    "    path = os.path.join(parent_dir,str(time.time()))\n",
    "    mode=0o666\n",
    "    os.mkdir(path, mode)\n",
    "    timed = str(datetime.datetime.now().today()).replace(\":\",\" \")+\".jpg\"\n",
    "    img.save(f\"{path}/{timed}\")\n",
    "    \n",
    "# create the bottom  right frame \n",
    "bottom_right_frame = tk.Frame(right_frame,width=620,height=425)\n",
    "bottom_right_frame.config(background=\"gray\")\n",
    "bottom_right_frame.grid(row=1,column=1)\n",
    "# create the top bottom right frame \n",
    "top_bottom_right_frame = tk.Frame(bottom_right_frame,width=620,height=65)\n",
    "top_bottom_right_frame.grid(row=0,column=1, pady=20)\n",
    "# some elements \n",
    "tk.Label(top_bottom_right_frame, text=\"Information About Searching Person\",fg=\"white\",bg=\"grey\", font=\"Helvetica 14 bold\").grid(row=0,column=0)\n",
    "# create the bottom bottom right frame \n",
    "bottom_bottom_right_frame = tk.Frame(bottom_right_frame ,bg=\"grey\",width=620,height=360)\n",
    "bottom_bottom_right_frame.grid(row=1,column=1)\n",
    "# some elements \n",
    "bf = tk.LabelFrame(bottom_bottom_right_frame, bg=\"grey\" ,width=620,height=360)\n",
    "bf.grid(row=0,column=0)\n",
    "\n",
    "def Search():\n",
    "    bf2 = tk.LabelFrame(bf, bg=\"gray\" ,width=620,height=360)\n",
    "    bf2.grid(row=0,column=1,rowspan=3,sticky=\"E\",ipadx=0,columnspan=1)\n",
    "    bf2.grid_propagate(False)\n",
    "    tk.Label(bf2, text=f\"Match Found   : {msgg}\",fg=\"red\", font=\"Helvetica 14 bold\").grid(row=1,column=0,padx=0,pady=13)\n",
    "    tk.Label(bf2, text=f\"Date Found    : {dateFound}\", font=\"Helvetica 14 bold\").grid(row=2,column=0,padx=0,pady=13)\n",
    "    tk.Label(bf2, text=f\"Location Found: {Location}\", font=\"Helvetica 14 bold\").grid(row=3,column=0,padx=0,pady=13)\n",
    "DetectOnvideo()\n",
    "\n",
    "\n",
    "window.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97fd6b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
